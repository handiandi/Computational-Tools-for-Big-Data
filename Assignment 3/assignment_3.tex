\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} 
\usepackage{amsmath,amssymb,graphicx}
\usepackage{cleveref}
\usepackage{url}
\usepackage{graphicx}
\usepackage[export]{adjustbox}

% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{12}  % for normal
\DeclareUnicodeCharacter{00D6}{Ö}
\DeclareUnicodeCharacter{00DC}{Ü}
\DeclareUnicodeCharacter{00E4}{ä}
\DeclareUnicodeCharacter{00E4}{ä}

% Custom colors
\usepackage{color}

\definecolor{output_background}{rgb}{0.2, 0.2, 0.2}
\definecolor{gray}{rgb}{0.5, 0.5, 0.5}
\definecolor{purple}{rgb}{0.6, 0.1, 0.9}
\usepackage{listings}

% Python style for highlighting
\newcommand\pythonstyle{\lstset{
language=python,
breaklines=true,
basicstyle=\ttfamily\small,
otherkeywords={1, 2, 3, 4, 5, 6, 7, 8 ,9 , 0, -, =, +, [, ], (, \), \{, \}, :, *, !},             % Add keywords here
keywordstyle=\color{blue},
emph={class, pass, in, for, while, if, is, elif, else, not, and, or, OR
    def, print, exec, break, continue, return},
emphstyle=\color{black}\bfseries,
emph={[2]True, False, None, self},
emphstyle=[2]\color{purple},
emph={[3]from, import, as},
emphstyle=[3]\color{blue},
stringstyle=\color{red},
frame=tb,
showstringspaces=false,
morecomment=[s]{"""}{"""},
commentstyle=\color{gray},
rulesepcolor=\color{blue},
title=\lstname
}}

% Python style for output highlighting
\newcommand\pythonoutputstyle{\lstset{
backgroundcolor=\color{output_background},
rulecolor=\color{output_background},
basicstyle=\ttm\small\color{white},
showstringspaces=false,
inputencoding=utf8,
extendedchars=true,
literate=%
    {á}{{\'a}}1
    {č}{{\v{c}}}1
    {ď}{{\v{d}}}1
    {é}{{\'e}}1
    {ě}{{\v{e}}}1
    {í}{{\'i}}1
    {ň}{{\v{n}}}1
    {ó}{{\'o}}1
    {ř}{{\v{r}}}1
    {š}{{\v{s}}}1
    {ť}{{\v{t}}}1
    {ú}{{\'u}}1
    {ů}{{\r{u}}}1
    {ý}{{\'y}}1
    {ž}{{\v{z}}}1
    {Á}{{\'A}}1
    {Č}{{\v{C}}}1
    {Ď}{{\v{D}}}1
    {É}{{\'E}}1
    {Ě}{{\v{E}}}1
    {Í}{{\'I}}1
    {Ň}{{\v{N}}}1
    {Ó}{{\'O}}1
    {Ř}{{\v{R}}}1
    {Š}{{\v{S}}}1
    {Ť}{{\v{T}}}1
    {Ú}{{\'U}}1
    {Ů}{{\r{U}}}1
    {Ý}{{\'Y}}1
    {Ž}{{\v{Z}}}1
    {Ö}{{\"{O}}}1
    {ö}{{\"{o}}}1
    {Ü}{{\"{U}}}1
    {ü}{{\"{u}}}1   
    {ß}{{\ss}}1
    {ä}{{\"{a}}}1
    {é}{{\'{e}}}1
    {ô}{{\^{o}}}1
    {â}{{\^{a}}}1
    {è}{{\`{e}}}1
}}


\lstnewenvironment{pythonOutput}[1][]
{
\pythonoutputstyle
\lstset{#1}
}
{}

% Python for inline
\newcommand\pythonoutput[1]{{\pythonoutputstyle\lstinline!#1!}}


% Python for external files
\newcommand\pythonexternal[2][]{{
\pythonstyle
\lstinputlisting[#1]{#2}}}

\title{Assignment 3\\02807 Computational Tools for Big Data}
\author{S \& A}
\date{26th October 2015}
\usepackage[cm]{fullpage}
\begin{document}

\maketitle
\newpage
%-------------- Week 5 ---------------------
\section{Exercise 8.1}
\textbf{Short recap of the exercise}\\
\textit{Define and implement a MapReduce job to count the occurrences of each word in a text file. Document that it works with a small example.}\\
~\\
\textbf{Overview}\\
We make the required method: mapper and reducer.   \\
The mapper takes a line at the time as value, then loops the word in the lijne through by splitting the line. It "calls" the reducer with the word as key and 1 as value. The reducer sums the valuee by key and yields the result. 
\\*
~\\
\textbf{Code}
\pythonexternal{"../Lesson 8/exercise-8-1.py"}
~\\
\textbf{Input}
\begin{pythonOutput}
der var en gang en mand
der booede i en spand
spanden var af ler
nu kan jeg ikke mer
\end{pythonOutput}
\textbf{Output}
\begin{pythonOutput}
"af"    1
"booede"    1
"der"   2
"en"    3
"gang"  1
"i" 1
"ikke"  1
"jeg"   1
"kan"   1
"ler"   1
"mand"  1
"mer"   1
"nu"    1
"spand" 1
"spanden"   1
"var"   2
\end{pythonOutput}
\textbf{Explanation of output and discussion}\\
We can see it returns the key (word) and the sum of the value (original the ones). As result we can see there is 3 occurrences of the word 'er' and 2 of the word 'der'. ~\\
If we them manually (from the text in input), we can see it is true.
~\\

\section{Exercise 8.2}
\textbf{Short recap of the exercise}\\
\textit{Define and implement a MapReduce job that determines if a graph has an Euler tour (all vertices have even degree) where you can assume that the graph you get is connected.
It is fine if you split the file into 5 different files. You do not need to keep the node and edge counts in the top of the file.}\\
~\\
\textbf{Overview}\\
Besides of the required mapper/reducer method, we have and additional reducer (reducer2) and a steps method. ~\\
The steps method tells MrJob in which order the oher method should run. In our case the mapper and reducer should run, and the reducer2. reducer2 reduces the yield result from reducer, where the logic is as followed:

\begin{itemize}
  \item \textbf{mapper} takes each line and split it into from- and to-edges. Then it yieldes these two as key with value 1
  \item \textbf{reducer} sums the values of the key, as we did in exercise 1
  \item \textbf{reducer2} check if all values of the key is even\\
\end{itemize}
~\\
We have split the input file in 5 files and the we call the script wirg the following command: ~\\
ls graph*.txt | xargs -n1 ./exercise-2.py -q \\
~\\
This run the script with all files as arguments, one-by-one in the correct order (1,2,...,5)

~\\
\textbf{Code}
\pythonexternal{"../Lesson 8/exercise-2.py"}
~\\
\textbf{Output}
\begin{pythonOutput}
"Has Euler Tour"    true
"Has Euler Tour"    false
"Has Euler Tour"    true
"Has Euler Tour"    true
"Has Euler Tour"    false

\end{pythonOutput}


\section{Exercise 8.3}
\textbf{Short recap of the exercise}\\
\textit{Implement the MapReduce job from the lecture which finds common friends (note that for the Facebook file, you need to extend the job to convert from a list of edges to the format from the slides – do this with an additional map/reduce job).}\\
~\\
\textbf{Overview}\\
We have split this assignment in two: one for the example in the slides, and one for the facebook file. ~\\
\textbf{For the slides example}

\textbf{For the facebook file}
~\\
\textbf{Code - Slides example}
\pythonexternal{"../Lesson 8/exercise-3-1.py"}
\textbf{Output - Slides example}
\begin{pythonOutput}
["A", "B"]  ["C", "D"]
["A", "C"]  ["B", "D"]
["A", "D"]  ["B", "C"]
["B", "C"]  ["A", "D", "E"]
["B", "D"]  ["A", "C", "E"]
["B", "E"]  ["C", "D"]
["C", "D"]  ["A", "B", "E"]
["C", "E"]  ["B", "D"]
["D", "E"]  ["B", "C"]


\end{pythonOutput}
\textbf{Code - Facebook file}
\pythonexternal{"../Lesson 8/exercise-3-2.py"}
\textbf{Output - Facebook file}
\begin{pythonOutput}
[0, 100]    [119, 150, 163, 189, 217, 269, 323, 64]
[0, 101]    [180, 187, 194, 204, 24, 242, 249, 254, 266, 299, 302, 317, 330, 346, 53, 80, 92, 
             94]
[0, 102]    [175, 227, 263, 296, 99]
[0, 103]    [136, 169, 172, 185, 200, 211, 25, 252, 271, 285, 323, 339, 56, 7, 98]
[0, 104]    [109, 113, 122, 123, 128, 142, 169, 186, 188, 200, 203, 21, 212, 239, 25, 252, 26, 
             271, 277, 295, 303, 318, 322, 325, 332, 344, 45, 55, 56, 67, 98]
[0, 105]    [119, 148, 21, 236, 25, 257, 272, 277, 280, 315, 39, 69, 9]
[0, 106]    [169, 231, 238, 29, 329, 332, 88]
[0, 107]    [171, 58]
[0, 108]    [127, 159, 184, 197, 21, 251, 272, 281, 284, 320, 36, 57]
[0, 109]    [104, 118, 119, 122, 13, 142, 148, 158, 169, 186, 200, 203, 21, 229, 239, 252, 26, 
             271, 277, 285, 295, 297, 303, 304, 31, 314, 322, 323, 324, 325, 331, 332, 50, 56, 
             67, 98]


\end{pythonOutput}


\section{Exercise 8.4}
\textbf{Short recap of the exercise}\\
\textit{Make a MapReduce job which counts the number of triangles in a graph.}\\
~\\
\textbf{Overview}\\


~\\
\textbf{Code}\\
%\pythonexternal{"../Lesson 5/exercise5-4.py"}
~\\
\textbf{Output}
\begin{pythonOutput}

\end{pythonOutput}



%-------------- Week 9 ---------------------
\section{Exercise 9.1}
\textbf{Short recap of the exercise}\\
\textit{Write a Spark job to count the occurrences of each word in a text file. Document that it works with a small example}\\
~\\
\textbf{Overview}
~\\
Following is a summarization of the comments in the file. 
\begin{enumerate}
  \item Extract lines in the file
  \item Splitting the lines into words
  \item Creating a pair for each word in the form ( word , count ) where count is the occurrence of the word , set to 1
  \item Counting the words
  \item Get the result and sort it based on count
  \item Print out the result\\
\end{enumerate}
~\\
\textbf{Code}\\
\pythonexternal{"../Lesson 9/exercise-9-1.py"}~\\
\textbf{Output}~\\
~\\
\textbf{Explanation of code and discussion}\\

\section{Exercise 9.2}
\textbf{Short recap of the exercise}\\
\textit{Write a Spark job that determines if a graph has an Euler tour (all vertices have even degree) where you can assume that the graph you get is connected.~\\
It is fine if you split the file into 5 different files. You do not need to keep the node and edge counts in the top of the file.}\\
~\\
\textbf{Overview}
As in the exercise in Week 8, we have splittet the file into 5 different files. ~\\
We have created a python function 'haseulertour' which take a filename string as argument. \\
~\\
The following is a step-by-step explaination of the code (primarily the function). 
\begin{enumerate}
  \item Loading in the file
  \item Creating a pair of integer values in the form (fromnode , tonode), by splitting on whitespace
  \item Creating a list of pairs in the form [(fromnode , tonode), (tonode , fromnode)]
  \item Creating a pair for each node in position 1 of the pairs in the list. The new pair has the form (node, count) where count is the occurrence of the node, set to 1
  \item We use reduceByKey to summerize the values
  \item filter-function find those whos values are not even
  \item If the count of result from filter-function is 0, return true, else return false 
  \item Print out the result\\
\end{enumerate}
~\\
\textbf{Code}\\
\pythonexternal{"../Lesson 9/exercise-9-2.py"}~\\
\textbf{Output}~\\

~\\
\textbf{Explanation of code and discussion}\\
 ~\\

\section{Exercise 9.3}
\textbf{Short recap of the exercise}\\
\textit{Compute the following things using Spark:
\begin{enumerate}
    \item What are the 10 networks I observed the most, and how many times were they observed? Note: the bssid is unique for every network, the name (ssid) of the network is not necessarily unique.
    \item What are the 10 most common wifi names? (ssid)
    \item What are the 10 longest wifi names? (again, ssid)
\end{enumerate}}
\textbf{Overview}
\textbf{Code}
\pythonexternal{"../Lesson 9/exercise-9-3.py"}~\\
\textbf{Output}
\textbf{Explanation of code and discussion}



%-------------- Week 10 ---------------------
\section{Exercise 10.1}
\textbf{Short recap of the exercise}
\textit{}
\textbf{Overview}
\textbf{Code}\\
%\pythonexternal{"../Lesson 7/bloom_filter.py"}
~\\
\textbf{Output}
\begin{pythonOutput}

\end{pythonOutput}
\textbf{Explanation of code and discussion}\\


\section{Exercise 10.2}
\textbf{Short recap of the exercise}\\
\textit{}\\
~\\
\textbf{Overview}\\

~\\
\textbf{Code}\\
%\pythonexternal{"../Lesson 7/flajolet_martin.py"}
~\\
\textbf{Output}
\begin{pythonOutput}

\end{pythonOutput}
\textbf{Explanation of code and discussion}\\

%-------------- Week 11 ---------------------
\section{Exercise 11.1}
\textbf{Short recap of the exercise}\\
\textit{Train a random forest classifier to predict the topic earn in the articles, then implement it using feature hashing with 1000 buckets}\\
~\\
\textbf{Overview}
\textbf{Code}\\
\pythonexternal{"../Lesson 11/exercise_11_1.py"}
~\\
\textbf{Output}
\begin{pythonOutput}
Accuracy using a bag-of-words representation: 
(10377, 70793)
0.94894026975
Accuracy using feature-hashing with 2 buckets:
(10377, 2)
0.72591522158
Accuracy using feature-hashing with 10 buckets:
(10377, 10)
0.879094412331
Accuracy using feature-hashing with 100 buckets:
(10377, 100)
0.920038535645
Accuracy using feature-hashing with 500 buckets:
(10377, 500)
0.936416184971
Accuracy using feature-hashing with 1000 buckets:
(10377, 1000)
0.930154142582

\end{pythonOutput}
\textbf{Explanation of code and discussion}\\
We implemented feature-hashing using the Exercise description and the Lesson 11 slides\footnote{\url{https://www.dropbox.com/s/8vh8nyywttf5y6e/hashing.pdf?dl=0}}.\\ In the articles dataset we found that 3776 articles contained the topic earn out of the total of 10377 articles, by simply guessing this would mean an accuracy of 63.611\%. In the output we can see the shape and accuracies of feature-hashing with a number of buckets. We find that even with only 2 buckets, the accuracy is 72.591\%, and except for the case of 1000 buckets, for a bigger number of buckets the accuracy is nearing the accuracy of the bag-of-words representation. Why the accuracy is lower for 1000 buckets than for 500 buckets we don't know. For the bag-of-words representation with 70793 features the accuracy is 94.894\% and for feature-hashing with 1000 buckets it is 93.015\%.

\section{Exercise 11.2}
\textbf{Short recap of the exercise}\\
\textit{}\\
~\\
\textbf{Overview}\\

~\\
\textbf{Code}\\
%\pythonexternal{"../Lesson 7/flajolet_martin.py"}
~\\
\textbf{Output}
\begin{pythonOutput}

\end{pythonOutput}
\textbf{Explanation of code and discussion}\\


\end{document}
